# Script for Week 4 Assignment

# for this exercise we will be using the dplyr package, if you do not have it already installed, run the following line.
#install.packages('dplyr')

# We first load the library we will be using. In this case, we will only need one.
library(dplyr)

# We create a function that we will use later one to format the labels of our dataframe into a more comprehensive or understandable format
# The input of the function is a dataframe, the it takes the names of the dataframe and searches for a number of regular expressions to replace them
# it assigns back the new names to the dataframe passed to the function and return the new renamed dataframe, so we can easily assign it to a variable.
format.lables <- function(x){
        tmp <- gsub(pattern = 't([A-Z])', replacement = 'time\\1', colnames(x), fixed = FALSE, perl = TRUE)
        tmp <- gsub(pattern = 'f([A-Z])', replacement = 'frequency\\1', tmp, fixed = FALSE, perl = TRUE)
        tmp <- gsub(pattern = 'Acc', replacement = 'Acceleration', tmp, fixed = TRUE)
        tmp <- gsub(pattern = 'Gyro', replacement = 'Gyroscope', tmp, fixed = TRUE)
        tmp <- gsub(pattern = '([a-z])([A-Z])', replacement = '\\1.\\2', tmp, fixed = FALSE, perl = TRUE)
        colnames(x) <- tmp
        return(x)
}

#We declare the Url where our data is located and then download it into our working directory. Then, we unzip its content into a folder.
fileUrl <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
download.file(fileUrl, 'smartphoneData.zip')
unzip(zipfile = 'smartphoneData.zip')

# in the next two steps we read the files containing labels or names for the variables and activities.
features.labels <- tbl_df(read.table('./UCI HAR Dataset/features.txt', header = FALSE, as.is = TRUE, col.names = c('id', 'name')))
activity.labels <- tbl_df(read.table('./UCI HAR Dataset/activity_labels.txt', header = FALSE, as.is = c(TRUE, FALSE), col.names = c('id', 'activity.name')))

# Test files processing

# We load the subjects of the experiment, the IDs of the acctivities they were performing and the data generated by the device.
subjects.test.df <- tbl_df(read.table('./UCI HAR Dataset/test/subject_test.txt', col.names = 'subject', as.is = TRUE))
y.test.df <- tbl_df(read.table('./UCI HAR Dataset/test/y_test.txt', col.names = 'activity', as.is = TRUE))
X.test.df <- tbl_df(read.table('./UCI HAR Dataset/test/X_test.txt', col.names = features.labels$name, as.is = TRUE))


# we use the data generated by the devices as starting point. We then add the subjects and the activity IDs as new columns, pairing them with each row.
# Now, we merge the dataframe with the y.test.df, which contains the names for each activity, which is more descriptive than a simple ID.
# Lastly, we reorder the columns to see first the relevant information about the subject generating the observation and the activity s/he was doing
# and then everything else, the rest of the columns.
test.df <- X.test.df %>%
        mutate(subject = factor(subjects.test.df$subject), activity.id = factor(y.test.df$activity)) %>%
        merge(y = activity.labels, by.x = 'activity.id', by.y = 'id', all.x = TRUE) %>%
        select(subject, activity.id, activity.name, everything()) %>%
        tbl_df()

# Train files processing

#same as described for test files processing.
subjects.train.df <- tbl_df(read.table('./UCI HAR Dataset/train/subject_train.txt', col.names = 'subject', as.is = TRUE))
y.train.df <- tbl_df(read.table('./UCI HAR Dataset/train/y_train.txt', col.names = 'activity', as.is = TRUE))
X.train.df <- tbl_df(read.table('./UCI HAR Dataset/train/X_train.txt', col.names = features.labels$name, as.is = TRUE))

#same as described for test files processing.
train.df <- X.train.df %>%
        mutate(subject = factor(subjects.train.df$subject), activity.id = factor(y.train.df$activity)) %>%
        merge(y = activity.labels, by.x = 'activity.id', by.y = 'id', all.x = TRUE) %>%
        select(subject, activity.id, activity.name, everything()) %>%
        tbl_df()

# Once we've got both df cleaned, we bind them with rbind. Which maintains the number of columns and sum the number of observations.
df <- rbind(test.df, train.df)

# We now create a new df selecting only the names that contains mean or std data, as requested by the exercise. We use text processing for that.
mean.std.df <- select(df, subject, activity.name, grep(pattern = 'mean.', x = colnames(df), fixed = TRUE), grep(pattern = 'std', x = colnames(df), fixed = TRUE))

# Here is the point where we use the function created at the begining, to format the labels into a more comprehensive format.
mean.std.df <- format.lables(mean.std.df)

# With our df cleaned, we created a whole new df (as requested on the exercise) with the mean of each of the resulting variables grouped by the subject
# and the activity s/he was doing during the experiment.
summarized.df <- mean.std.df %>%
        group_by(subject, activity.name) %>%
        summarize_all(funs(mean))

#Lastly, we save the df into a txt file in order to upload it.
write.table(x = summarized.df, file = 'final.df.txt', row.names = FALSE)

#Run the code below to see the main dfs created along the exercise.
#View(df)
#View(mean.std.df)
#View(summarized.df)
